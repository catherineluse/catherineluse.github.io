---
layout: post
title: In Defense of Moderation
date: 2020-11-22 21:00:01 -0700
categories: side-project
---


If you are reading this and you are anti-censorship, and you believe people should be able to say whatever you they want on the Internet, regardless of whether it's a conspiracy theory or a racist lie, let me tell you why we should be friends.

(Note: To be clear, this post isn't about government censorship.)

# Truth vs. Freedom

I think that while you and I disagree, we also probably have core values in common. I think you and I probably value both freedom of speech and the truth. It's just that you value freedom of speech over the truth, and I value the truth more than the freedom of speech. It's not that we don't have the same values. It's a matter of priorities.

Maybe you wish we lived in a world where the truth would always win, a world where the truth stands on its own. A world where people don't believe lies on social media because they have common sense and critical thinking skills, and they're always in the mood to apply their critical thinking skills, even while casually scrolling through their feeds and consuming information for entertainment. Applying critical thinking skills to fact-check the content that you consume requires a significant amount of effort and an interruption of your entertainment consumption, and I would argue that in the context of an app designed for entertainment or infotainment, it's too much to ask of the average consumer.

# Emotions Matter

I don't live in a perfectly rational world. I live in a world where even the most intelligent and logical people have human vulnerabilities and emotions. Not every smart person has their brain turned on all the time. Not every logical person has the ability to shut out content that makes them feel grief, fear, outrage, or a combination of all three.

In fact, many logical people are drawn toward the most sensational posts because they want to focus on what seem to be the biggest problems in the world - because the world's biggest problems deserve our attention the most, don't they? It's a natural human trait to get sucked down a rabbit hole of information - or misinformation, or a conspiracy theory - when you stumble upon something that feels like an enormous problem.

So if you're opposed to moderation, deplatforming, and banning people from platforms for spreading misinformation, I ask you to do this: I ask you to feel sympathy for people who have trouble differentiating truth from lies. I ask you to give them the benefit of the doubt. Because in my opinion, it's not always their fault, and it's not uncommon for even highly successful and/or educated people to fall for emotionally manipulative tactics. What's more, I think if you asked most people who believe conspiracy theories if they would like to know the truth, or if they would like to be lied to, most would prefer to know the truth.

# The Responsibility to Promote the Truth

Not everyone can easily differentiate the truth from lies, and I believe the responsibility to accept the truth and reject lies is not solely the responsibility of the individual consumer. While the truth should be able to prevail on principle, I believe that it will never prevail on platforms with large amounts of user-generated content, particularly when the platform is designed to maximize user engagement as the highest priority. That is why more platforms need to be built to support fair and transparent moderation from the ground up, not as an afterthought.

# Leadership in Moderation

I see social media platform moderation as a form of leadership, not censorship. I think in any given social situation in life, there are always unwritten rules about what you should and should not do, and enforcement of those rules isn't an act of censorship. It's an act of leadership. In my experience, most people prefer at least a nominal amount of leadership in a public context so that they know the purpose of the group and what the expectations are. When groups don't have good leadership, they lack a shared purpose, or they easily diverge from their original purpose. Moderation is important to help a group achieve its intended purpose.

In an online context, a good moderator is a type of leader who can keep online discussions moving forward in a constructive and organized way that is compatible with the group's shared purpose, whatever that may be. In an ideal system, anyone whose post is removed would believe that the moderation action is fair, and that they had the same opportunities to contribute as anyone else. It is the moderation team's responsibility to cultivate that level of trust.

And it's important to cultivate that trust, because moderation is not just what removes low-quality posts from a discussion. It is also what motivates the people who contribute to discussions the most to return to the community again and again.

# Moderation by the People, for the People

Moderation systems also need to be designed by and for ordinary people to enforce context-specific rules, and to take the burden of moderation off of admins who don't have the context necessary to take moderation actions that make sense for a specific community. The only way to cultivate trust in the moderation for a given community is for the majority of moderation actions to be performed by actual community members, not by admins.

Moderation can be abused, but I think that means we need better moderation systems that have proper checks and balances to counter the abuse, such as gradually increasing moderation actions, transparent records of all moderation actions, and standardized practices for appealing moderation decisions and removing bad moderators.
